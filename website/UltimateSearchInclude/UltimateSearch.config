<ultimateSearch>
	<configuration>
		<appSettings> 
			<!-- Starts scanning (crawling and indexing) the files under the specified
				directories and continues this process recursively until it covers 
			 	all subdirectories underneath.
			     If you don't specify anything in scanDirectoryList, scanXmlList or scanUrlList
				it scans the files and folders under the current web application by default.
			     Note that if you enter anything in scanDirectoryList you also need to set
				mapPathList below so that it can map to the virtual path to crawl properly.
			     For example, you may have a list as below:
				<scanDirectoryList>
					<scanDirectory>c:\local_dev_sites\local.rei.com\</scanDirectory>
					<scanDirectory>c:\inetpub\wwwroot\WebApplication2\PublicFolder</scanDirectory>
				</scanDirectoryList>
			 -->
			

			<!-- Parses the local XML file specified by "filePath" to extract the urls
				from the elements or attributes specified by "urlXPath".
			     You can list one or more website navigation files such as UltimateMenu, 
				UltimatePanel and UltimateSitemap source XML files, each one specified 
				in a separate "scanXml" element.
			     Note that "urlXPath" is case-sensitive. Also note that you can set "filePath"
				in three different forms.
			     For example, you may have a list as below:
				<scanXmlList>
					<scanXml>
						<filePath>http://localhost/WebApplication1/menu.xml</filePath>
						<urlXPath>//@URL</urlXPath>
					</scanXml>
					<scanXml>
						<filePath>C:\inetpub\wwwroot\WebApplication1\panel.xml</filePath>
						<urlXPath>//@URL</urlXPath>
					</scanXml>
					<scanXml>
						<filePath>~/web.sitemap</filePath>
						<urlXPath>//@url</urlXPath>
					</scanXml>
				</scanXmlList>
			 -->
			<scanXmlList>
				<scanXml>
					<filePath></filePath>
					<urlXPath></urlXPath>
				</scanXml>
			</scanXmlList>

			<!-- Starts scanning (crawling and indexing) with each of the following urls and 
				continues with the urls inside each page until it covers all urls within 
				each domain. You can list multiple domains, home pages, sitemap pages, or 
				any other url.
			     If you specify a subdirectory in your domain, it will discard
				the links above that level. Therefore, you should specify the highest possible
				level in your domain and any other domain that you want to index.
			     If you have a link to a different domain, and you don't have that domain
				listed in scanUrlList, then those links will be excluded automatically.
			     If you set scanUrl to a document such as a PDF file as in the following example
				you should also add "pdf" to ifilterList below.
			     Note that scanUrl can be set to any URL that opens as a page
				in your browser window. If you set it to a directory like WebApplication2 below
				you should enable default documents on the Documents tab of the IIS settings.
			     For example, you may have a list as below:
				<scanUrlList>
					<scanUrl>http://localhost/WebApplication1/WebForm1.aspx</scanUrl>
					<scanUrl>http://localhost/WebApplication2</scanUrl>
					<scanUrl>http://localhost/WebApplication3/Sitemap.aspx</scanUrl>
					<scanUrl>http://localhost/Karamasoft/ASP.NET2.0/UltimateSearch/v3.2/Demos/VB/Samples/LoadDocuments/Karamasoft-UISuite.pdf</scanUrl>
				</scanUrlList>
	 -->		
			<scanUrlList>
				<scanUrl>http://www.richtemplate.com</scanUrl>
				<scanUrl>http://us.richtemplate.com</scanUrl>
				<scanUrl>http://ca.richtemplate.com</scanUrl>
				<scanUrl>http://br.richtemplate.com</scanUrl>
			</scanUrlList>

			<!-- Urls starting with the following prefixes will be discarded.
			     Note that you can also use the robots.txt file to disallow paths, or
				 robots meta tags to set noindex and nofollow flags in each page.
			     You may visit http://www.robotstxt.org/wc/exclusion-admin.html
				 to get more familiar with the robots.txt file and meta tags.
			     If you don't specify anything it will exclude the UltimateSearchInclude
				 directory under the current web application by default.
			     For example, you may have a list as below:
				<excludePathList>
					<excludePath>http://localhost/WebApplication1/UltimateEditorInclude</excludePath>
					<excludePath>http://localhost/WebApplication1/UltimateSpellInclude</excludePath>
					<excludePath>http://localhost/WebApplication1/UltimateSearchInclude</excludePath>
					<excludePath>http://localhost/WebApplication1/WebForm2.aspx</excludePath>
					<excludePath>http://localhost/WebApplication2/HiddenFolder</excludePath>
				</excludePathList>
			 -->
			<excludePathList>
				<excludePath>http://www.richtemplate.com/admin</excludePath>
				<excludePath>http://www.richtemplate.com/UltimateSearchInclude</excludePath>
				<excludePath>http://www.richtemplate.com/UltimateSpellInclude</excludePath>
				<excludePath>http://www.richtemplate.com/richadmin</excludePath>
				<excludePath>http://www.richtemplate.com/app_code</excludePath>
				<excludePath>http://www.richtemplate.com/aspnet_client</excludePath>
				<excludePath>http://www.richtemplate.com/editor2</excludePath>
				<excludePath>http://www.richtemplate.com/iepngfix</excludePath>
				<excludePath>http://www.richtemplate.com/ig4sub</excludePath>
				<excludePath>http://www.richtemplate.com/js</excludePath>
				<excludePath>http://www.richtemplate.com/scripts</excludePath>
				<excludePath>http://www.richtemplate.com/skins</excludePath>
				<excludePath>http://www.richtemplate.com/_private</excludePath>
				<excludePath>http://www.richtemplate.com/_vti_cnf</excludePath>
				<excludePath>http://www.richtemplate.com/_vti_pvt</excludePath>
				<excludePath>http://www.richtemplate.com/_vti_script</excludePath>
				<excludePath>http://www.richtemplate.com/_vti_txt</excludePath>
				
				<excludePath>http://us.richtemplate.com/admin</excludePath>
				<excludePath>http://us.richtemplate.com/UltimateSearchInclude</excludePath>
				<excludePath>http://us.richtemplate.com/UltimateSpellInclude</excludePath>
				<excludePath>http://us.richtemplate.com/richadmin</excludePath>
				<excludePath>http://us.richtemplate.com/app_code</excludePath>
				<excludePath>http://us.richtemplate.com/aspnet_client</excludePath>
				<excludePath>http://us.richtemplate.com/editor2</excludePath>
				<excludePath>http://us.richtemplate.com/iepngfix</excludePath>
				<excludePath>http://us.richtemplate.com/ig4sub</excludePath>
				<excludePath>http://us.richtemplate.com/js</excludePath>
				<excludePath>http://us.richtemplate.com/scripts</excludePath>
				<excludePath>http://us.richtemplate.com/skins</excludePath>
				<excludePath>http://us.richtemplate.com/_private</excludePath>
				<excludePath>http://us.richtemplate.com/_vti_cnf</excludePath>
				<excludePath>http://us.richtemplate.com/_vti_pvt</excludePath>
				<excludePath>http://us.richtemplate.com/_vti_script</excludePath>
				<excludePath>http://us.richtemplate.com/_vti_txt</excludePath>

				<excludePath>http://ca.richtemplate.com/admin</excludePath>
				<excludePath>http://ca.richtemplate.com/UltimateSearchInclude</excludePath>
				<excludePath>http://ca.richtemplate.com/UltimateSpellInclude</excludePath>
				<excludePath>http://ca.richtemplate.com/richadmin</excludePath>
				<excludePath>http://ca.richtemplate.com/app_code</excludePath>
				<excludePath>http://ca.richtemplate.com/aspnet_client</excludePath>
				<excludePath>http://ca.richtemplate.com/editor2</excludePath>
				<excludePath>http://ca.richtemplate.com/iepngfix</excludePath>
				<excludePath>http://ca.richtemplate.com/ig4sub</excludePath>
				<excludePath>http://ca.richtemplate.com/js</excludePath>
				<excludePath>http://ca.richtemplate.com/scripts</excludePath>
				<excludePath>http://ca.richtemplate.com/skins</excludePath>
				<excludePath>http://ca.richtemplate.com/_private</excludePath>
				<excludePath>http://ca.richtemplate.com/_vti_cnf</excludePath>
				<excludePath>http://ca.richtemplate.com/_vti_pvt</excludePath>
				<excludePath>http://ca.richtemplate.com/_vti_script</excludePath>
				<excludePath>http://ca.richtemplate.com/_vti_txt</excludePath>

				<excludePath>http://br.richtemplate.com/admin</excludePath>
				<excludePath>http://br.richtemplate.com/UltimateSearchInclude</excludePath>
				<excludePath>http://br.richtemplate.com/UltimateSpellInclude</excludePath>
				<excludePath>http://br.richtemplate.com/richadmin</excludePath>
				<excludePath>http://br.richtemplate.com/app_code</excludePath>
				<excludePath>http://br.richtemplate.com/aspnet_client</excludePath>
				<excludePath>http://br.richtemplate.com/editor2</excludePath>
				<excludePath>http://br.richtemplate.com/iepngfix</excludePath>
				<excludePath>http://br.richtemplate.com/ig4sub</excludePath>
				<excludePath>http://br.richtemplate.com/js</excludePath>
				<excludePath>http://br.richtemplate.com/scripts</excludePath>
				<excludePath>http://br.richtemplate.com/skins</excludePath>
				<excludePath>http://br.richtemplate.com/_private</excludePath>
				<excludePath>http://br.richtemplate.com/_vti_cnf</excludePath>
				<excludePath>http://br.richtemplate.com/_vti_pvt</excludePath>
				<excludePath>http://br.richtemplate.com/_vti_script</excludePath>
				<excludePath>http://br.richtemplate.com/_vti_txt</excludePath>
			</excludePathList>

			<!-- You can exclude a portion of your pages in three different ways:
			     1. Use UltimateSearch_IgnoreBegin and UltimateSearch_IgnoreEnd tags
				to exclude everything between these tags from indexing.
			     2. Use UltimateSearch_IgnoreTextBegin and UltimateSearch_IgnoreTextEnd tags
				to exclude only the text between these tags from indexing, while following the links.
			     3. Use UltimateSearch_IgnoreLinksBegin and UltimateSearch_IgnoreLinksEnd tags
				to exclude only the links between these tags from indexing, while indexing the text.

			     See how you can define these ignore tags below:
			 -->

			<!-- UltimateSearch_IgnoreBegin -->
				<!-- Everything here will be ignored -->
			<!-- UltimateSearch_IgnoreEnd -->

			<!-- UltimateSearch_IgnoreTextBegin -->
				<!-- Text here will be ignored, but links will be followed -->
			<!-- UltimateSearch_IgnoreTextEnd -->

			<!-- UltimateSearch_IgnoreLinksBegin -->
				<!-- Links here will be ignored, but text will be indexed -->
			<!-- UltimateSearch_IgnoreLinksEnd -->

			<!-- Only the files with the following extensions will be scanned.
				Note that these files must be of text/html type so that they can be crawled
				properly. For non text/html file types you will need to use IFilters
				as explained in the ifilterList element below.
			 -->
			<includeFileTypeList>
				<includeFileType>asp</includeFileType>
				<includeFileType>aspx</includeFileType>
				<includeFileType>asmx</includeFileType>
				<includeFileType>ashx</includeFileType>
				<includeFileType>mspx</includeFileType>
				<includeFileType>php</includeFileType>
				<includeFileType>htm</includeFileType>
				<includeFileType>html</includeFileType>
				<includeFileType>txt</includeFileType>
			</includeFileTypeList>

			<!-- IFilters are used to open and parse the non text/html file types such as
				pdf, doc, xls, ppt, etc. that are not in the default includeFileTypeList above.
				You need to install the specific IFilter for each file type. You may visit
				http://www.ifilter.org to download the necessary IFilters for free.
				For Adobe IFilter for PDF, please use v5.0 first, and if it doesn't work
				try v6.0. Remember to reboot your machine after each IFilter installation.
			     Note that you don't need to install an IFilter for doc, xls, ppt since
				they already exist on Windows server. You only need to add the file extensions
				here in separate ifilter elements.
			     If the documents reside on your local machine or network you should set 
				the mapPathList element below to improve performance.
			     For example, you may have a list as below:
				<ifilterList>
					<ifilter>pdf</ifilter>
					<ifilter>doc</ifilter>
					<ifilter>xls</ifilter>
					<ifilter>ppt</ifilter>
				</ifilterList>
			 -->
			<ifilterList>
        <ifilter>pdf</ifilter>
        <ifilter>doc</ifilter>
        <ifilter>xls</ifilter>
        <ifilter>docx</ifilter>
        <ifilter>xlsx</ifilter>
        <ifilter>ppt</ifilter>
        <ifilter>txt</ifilter>	
      </ifilterList>

			<!-- Virtual to physical path mappings must be provided if you use scanDirectoryList.
				It is optional for ifilterList to improve performance.
			     For example, you may have a list as below:
				<mapPathList>
				    <mapPath>
				        <virtualPath>http://richtemplate.com</virtualPath>
				        <physicalPath>C:\inetpub\webRoot\richtemplate_com\website\</physicalPath>
				    </mapPath>
				    <mapPath>
				        <virtualPath>http://us.richtemplate.com</virtualPath>
				        <physicalPath>C:\inetpub\webRoot\richtemplate_com\website\/physicalPath>
				    </mapPath>
					<mapPath>
				        <virtualPath>http://am.richtemplate.com</virtualPath>
				        <physicalPath>C:\inetpub\webRoot\richtemplate_com\website\/physicalPath>
				    </mapPath>
				</mapPathList>
			 -->
			<mapPathList>
        <mapPath>
          <virtualPath>http://www.richtemplate.com</virtualPath>
          <physicalPath>C:\Inetpub\webroot\richtemplate\website</physicalPath>
        </mapPath>
        <mapPath>
          <virtualPath>http://us.richtemplate.com</virtualPath>
          <physicalPath>C:\Inetpub\webroot\richtemplate\website</physicalPath>
        </mapPath>
		 <mapPath>
          <virtualPath>http://ca.richtemplate.com</virtualPath>
          <physicalPath>C:\Inetpub\webroot\richtemplate\website</physicalPath>
        </mapPath>
 <mapPath>
          <virtualPath>http://br.richtemplate.com</virtualPath>
          <physicalPath>C:\Inetpub\webroot\richtemplate\website</physicalPath>
        </mapPath>
			</mapPathList>

			<!-- When you deploy your web application to a production/hosting environment, 
				you may not have the ability to crawl/index your website or you may not 
				have the necessary permissions to save your index files. In that case, you may build 
				your index file on your development/publishing machine, and then copy 
				the Index directory onto your production machine.
			     On your development/publishing machine, you have to provide "devProdMapPathList" 
				so that the generated index files have the urls point to the actual production 
				machine instead of your development machine. After copying the Index directory 
				onto the production machine you will also need to update the config file on that 
				machine to set "saveIndex", "saveEventLog", and "saveSearchLog" to "false" 
				since you're not allowed to write onto that machine.
			     On your production/hosting machine, open the UltimateSearch.admin.aspx page in IE, 
				and click "Load Copied Index" in order to load the copied index.
			     For example, you may have a list as below:
				<devProdMapPathList>
					<devProdMapPath>
						<devPath>local.rei.com</devPath>
						<prodPath>www.mydomain.com</prodPath>
					</devProdMapPath>
					<devProdMapPath>
						<devPath>myVirtualDir</devPath>
						<prodPath>subdomain.mydomain.com</prodPath>
					</devProdMapPath>
				</devProdMapPathList>
			 -->
			

			<!-- Default documents under each directory. When you specify this list,
				 it won't index the directory url and the default document url at the same time.
			     For example, you may have a list as below:
				<defaultDocumentList>
					<defaultDocument>default.aspx</defaultDocument>
					<defaultDocument>default.asp</defaultDocument>
					<defaultDocument>default.htm</defaultDocument>
					<defaultDocument>index.htm</defaultDocument>
				</defaultDocumentList>
			 -->
			<defaultDocumentList>
				<defaultDocument></defaultDocument>
			</defaultDocumentList>

			<!-- Following words will not be indexed.
				 No need to list words that are shorter than
				 "minWordLength" specified in this configuration file. -->
			<stopWordList>
				<stopWord>about</stopWord>
				<stopWord>after</stopWord>
				<stopWord>all</stopWord>
				<stopWord>also</stopWord>
				<stopWord>an</stopWord>
				<stopWord>and</stopWord>
				<stopWord>another</stopWord>
				<stopWord>any</stopWord>
				<stopWord>are</stopWord>
				<stopWord>as</stopWord>
				<stopWord>at</stopWord>
				<stopWord>be</stopWord>
				<stopWord>because</stopWord>
				<stopWord>been</stopWord>
				<stopWord>before</stopWord>
				<stopWord>being</stopWord>
				<stopWord>between</stopWord>
				<stopWord>both</stopWord>
				<stopWord>but</stopWord>
				<stopWord>by</stopWord>
				<stopWord>came</stopWord>
				<stopWord>can</stopWord>
				<stopWord>come</stopWord>
				<stopWord>could</stopWord>
				<stopWord>did</stopWord>
				<stopWord>do</stopWord>
				<stopWord>does</stopWord>
				<stopWord>each</stopWord>
				<stopWord>else</stopWord>
				<stopWord>for</stopWord>
				<stopWord>from</stopWord>
				<stopWord>get</stopWord>
				<stopWord>got</stopWord>
				<stopWord>has</stopWord>
				<stopWord>had</stopWord>
				<stopWord>he</stopWord>
				<stopWord>have</stopWord>
				<stopWord>her</stopWord>
				<stopWord>here</stopWord>
				<stopWord>him</stopWord>
				<stopWord>himself</stopWord>
				<stopWord>his</stopWord>
				<stopWord>how</stopWord>
				<stopWord>if</stopWord>
				<stopWord>in</stopWord>
				<stopWord>into</stopWord>
				<stopWord>is</stopWord>
				<stopWord>it</stopWord>
				<stopWord>its</stopWord>
				<stopWord>just</stopWord>
				<stopWord>like</stopWord>
				<stopWord>make</stopWord>
				<stopWord>many</stopWord>
				<stopWord>me</stopWord>
				<stopWord>might</stopWord>
				<stopWord>more</stopWord>
				<stopWord>most</stopWord>
				<stopWord>much</stopWord>
				<stopWord>must</stopWord>
				<stopWord>my</stopWord>
				<stopWord>never</stopWord>
				<stopWord>now</stopWord>
				<stopWord>of</stopWord>
				<stopWord>on</stopWord>
				<stopWord>only</stopWord>
				<stopWord>or</stopWord>
				<stopWord>other</stopWord>
				<stopWord>our</stopWord>
				<stopWord>out</stopWord>
				<stopWord>over</stopWord>
				<stopWord>re</stopWord>
				<stopWord>said</stopWord>
				<stopWord>same</stopWord>
				<stopWord>see</stopWord>
				<stopWord>she</stopWord>
				<stopWord>should</stopWord>
				<stopWord>since</stopWord>
				<stopWord>so</stopWord>
				<stopWord>some</stopWord>
				<stopWord>still</stopWord>
				<stopWord>such</stopWord>
				<stopWord>take</stopWord>
				<stopWord>than</stopWord>
				<stopWord>that</stopWord>
				<stopWord>the</stopWord>
				<stopWord>their</stopWord>
				<stopWord>them</stopWord>
				<stopWord>then</stopWord>
				<stopWord>there</stopWord>
				<stopWord>these</stopWord>
				<stopWord>they</stopWord>
				<stopWord>this</stopWord>
				<stopWord>those</stopWord>
				<stopWord>through</stopWord>
				<stopWord>to</stopWord>
				<stopWord>too</stopWord>
				<stopWord>under</stopWord>
				<stopWord>up</stopWord>
				<stopWord>use</stopWord>
				<stopWord>very</stopWord>
				<stopWord>want</stopWord>
				<stopWord>was</stopWord>
				<stopWord>way</stopWord>
				<stopWord>we</stopWord>
				<stopWord>well</stopWord>
				<stopWord>were</stopWord>
				<stopWord>what</stopWord>
				<stopWord>when</stopWord>
				<stopWord>where</stopWord>
				<stopWord>which</stopWord>
				<stopWord>while</stopWord>
				<stopWord>who</stopWord>
				<stopWord>will</stopWord>
				<stopWord>with</stopWord>
				<stopWord>would</stopWord>
				<stopWord>you</stopWord>
				<stopWord>your</stopWord>
			</stopWordList>

			<!-- Ignore words that contain only numeric characters such as 1234.
			 -->
			<add key="ignoreAllNumericWords" value="true" />

			<!-- Ignore words that contain both numeric and alphabetic characters such as ABC123.
			 -->
			<add key="ignoreMixedNumericWords" value="true" />

			<!-- Subdirectories under the UltimateSearchInclude directory.
				 Give full permission to the ASP.NET user (NETWORK SERVICE in Windows 2003)
				 on the Index and Log directories in order to save the index and log files properly.
			 -->
			<add key="indexDirectory" value="~/UltimateSearchInclude/Index" />
			<add key="logDirectory" value="~/UltimateSearchInclude/Log" />

			<!-- If you don't have write permission on your production server
				 you may set these flags to false.
			 -->
			<add key="saveEventLog" value="true" />
			<add key="saveSearchLog" value="true" />

			<!-- You may visit http://www.robotstxt.org/wc/exclusion-admin.html
				 to get more familiar with the robots.txt file and meta tags.
			 -->
			<add key="useRobotsFile" value="false" />
			<add key="useRobotsMeta" value="false" />

			<!-- If you want to keep the querystrings as part of the indexed urls
				 you should set this flag to false.
			 -->
			<add key="removeQueryString" value="false" />

			<!-- If you set this flag to true indexed urls will be case-sensitive,
				 i.e. search results may show both http://www.mydomain.com and
				 http://www.MyDomain.com if both links exist on your pages.
				 This feature is especially useful if the values in querystrings
				 need to be case-sensitive.
			 -->
			<add key="urlCaseSensitive" value="false" />

			<!-- Reindexes everything from scratch after the specified number of days.
				 For example, you can set the value to 7 to reindex everything once a week
			 -->
			<add key="frequencyInDaysForReindexFull" value="0" />

			<!-- Reindexes only the updated documents after the specified number of days.
				 For example, you can set the value to 7 to reindex changes only once a week
			 -->
			<add key="frequencyInDaysForReindexIncremental" value="1" />

			<!-- Reindexes everything from scratch whenever this file gets updated.
				 For example, you can set the value to ~/Samples/Cookbook/Index.htm
			 -->
			<add key="dependencyFileForReindexFull" value="" />

			<!-- Reindexes only the updated documents whenever this file gets updated.
				 For example, you can set the value to ~/Samples/Cookbook/Dessert/PoppySeedBundtCake.htm
			 -->
			<add key="dependencyFileForReindexIncremental" value="" />

			<!-- Maximum number of pages allowed to be indexed. There is no limitation on this setting.
				 You can set it to a larger number if you have enough memory and disk space to support.
			 -->
			<add key="maxPageCount" value="1000000" />

			<!-- Maximum number of characters to be read from each page. There is no limitation on this setting.
				 You can set it to a greater number if your pages are too big and you want to index
				 all page content.
			     Note that this value needs to be greater than the number of characters displayed
				 on a page because of the HTML tags and hidden text in the source of the page.
				 In other words you should take into account the actual number of characters
				 that you see when you make a view source on a page.
			 -->
			<add key="maxPageLength" value="1000000" />

			<!-- Minimum number of characters allowed in a word to be indexed.
				 Words with less number of characters won't be indexed.
			 -->
			<add key="minWordLength" value="3" />

			<!-- Maximum number of characters allowed in a word to be indexed.
				 Words with more number of characters won't be indexed.
			 -->
			<add key="maxWordLength" value="30" />

			<!-- Score page content differently based on its location.
				 If you set score to 0 (zero) then the words in that portion won't be indexed at all.
				 For example, you may set scoreUrl to 0 if you don't want the words in urls to be indexed.
			 -->
			<add key="scoreUrl" value="16" />
			<add key="scoreTitle" value="8" />
			<add key="scoreKeywords" value="4" />
			<add key="scoreDescription" value="2" />
			<add key="scoreText" value="1" />

      <!-- User-Agent to identify the originator of the HTTP request sent to the web server during crawling.
         Default value is "Karamasoft UltimateSearch Crawler". You can set it to a different value
           in order to make the web server render different output based on the connecting device.
         For example, you can set it to "BlackBerry8100/4.2.0 Profile/MIDP-2.0 Configuration/CLDC-1.1"
           if you want to index your website for people connecting from a mobile device like BlackBerry Pearl.
			 -->

            <!--<add key="userAgent" value="Karamasoft UltimateSearch Crawler" />-->
            <add key="userAgent" value="UltimateSearchUserAgent_r!cht3mp1@t3" />

			<!-- Proxy settings.
			 -->
			<add key="useDefaultProxy" value="true" />
			<add key="proxyAddress" value="" />
			<add key="proxyUsername" value="" />
			<add key="proxyPassword" value="" />
			<add key="proxyDomain" value="" />

			<!-- Network credentials.
			 -->
			<add key="useDefaultCredentials" value="true" />
			<add key="networkUsername" value="" />
			<add key="networkPassword" value="" />
			<add key="networkDomain" value="" />

		</appSettings>
	</configuration>
</ultimateSearch>
